{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109},{"sourceId":9457042,"sourceType":"datasetVersion","datasetId":5749006},{"sourceId":9457063,"sourceType":"datasetVersion","datasetId":5749023}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.models import load_model\nfrom time import sleep\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing import image\nimport cv2\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:59:59.017959Z","iopub.execute_input":"2024-09-22T16:59:59.018750Z","iopub.status.idle":"2024-09-22T16:59:59.023706Z","shell.execute_reply.started":"2024-09-22T16:59:59.018709Z","shell.execute_reply":"2024-09-22T16:59:59.022607Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from keras.losses import MeanSquaredError\n\n# Custom wrapper around MeanSquaredError, if needed\ndef mse(y_true, y_pred):\n    return MeanSquaredError()(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:07:11.599726Z","iopub.execute_input":"2024-09-22T17:07:11.600459Z","iopub.status.idle":"2024-09-22T17:07:11.606469Z","shell.execute_reply.started":"2024-09-22T17:07:11.600415Z","shell.execute_reply":"2024-09-22T17:07:11.605565Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from keras.saving import register_keras_serializable\n\n@register_keras_serializable(package='Custom', name='mse')\ndef mse(y_true, y_pred):\n    return MeanSquaredError()(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T17:07:59.670328Z","iopub.execute_input":"2024-09-22T17:07:59.670761Z","iopub.status.idle":"2024-09-22T17:07:59.678072Z","shell.execute_reply.started":"2024-09-22T17:07:59.670721Z","shell.execute_reply":"2024-09-22T17:07:59.676800Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom collections import deque\n\n# Load pre-trained models\nface_classifier = cv2.CascadeClassifier('/kaggle/input/haarcascade/haarcascade_frontalface_default.xml')\nage_model = load_model('age_model_100epochs.h5', custom_objects={'mse': mse})\ngender_model = load_model('gender_model_50epochs.h5', custom_objects={'mse': mse})\n\n# Gender labels\ngender_labels = ['Male', 'Female']\n\n# Video input path\ncap = cv2.VideoCapture(\"/kaggle/input/webcamfaces/3196096-uhd_3840_2160_25fps.mp4\")\n\n# Define the codec and create VideoWriter object to save the video\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 files\noutput_path = 'output_video.mp4'  # Output video path\nfps = int(cap.get(cv2.CAP_PROP_FPS))  # Get frames per second from the original video\nframe_width = int(cap.get(3))  # Get width of the frame\nframe_height = int(cap.get(4))  # Get height of the frame\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nage_predictions = deque(maxlen=50)  # Deque to store the last 50 age predictions\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        print(\"Finished processing video or error reading frame.\")\n        break\n    \n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n\n    for (x, y, w, h) in faces:\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 255), 2)\n        roi_color = frame[y:y+h, x:x+w]\n        roi_color = cv2.resize(roi_color, (200, 200), interpolation=cv2.INTER_AREA)\n\n        # Gender prediction\n        gender_predict = gender_model.predict(np.array(roi_color).reshape(-1, 200, 200, 3), verbose=0)\n        gender_predict = (gender_predict >= 0.5).astype(int)[:, 0]\n        gender_label = gender_labels[gender_predict[0]]\n        gender_label_position = (x, y+h+50)\n        cv2.putText(frame, gender_label, gender_label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 245, 11), 2)\n\n        # Age prediction\n        age_predict = age_model.predict(np.array(roi_color).reshape(-1, 200, 200, 3), verbose=0)\n        age = round(age_predict[0, 0])\n        \n        # Append the predicted age to the deque\n        age_predictions.append(age)\n\n        # Calculate the average of the last 50 age predictions\n        if age_predictions:\n            avg_age = round(np.mean(age_predictions))\n\n        age_label_position = (x+h, y+h)\n        cv2.putText(frame, \"Age=\" + str(avg_age), age_label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 245, 11), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(f\"Video saved at {output_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T18:43:54.917124Z","iopub.execute_input":"2024-09-22T18:43:54.917870Z"},"trusted":true},"execution_count":null,"outputs":[]}]}